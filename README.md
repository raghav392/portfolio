## ğŸ‘‹ Hi, Iâ€™m Thakur Raghavender Singh
ğŸš€ Data Engineer | Big Data | Cloud | ETL
ğŸ“ Austin, Texas | ğŸ“§ raghavenderthakur4@gmail.com  
[LinkedIn](#) | [GitHub](#) | [Portfolio](#) | [Medium](#)  

---

## ğŸ‘¨â€ğŸ’» About Me
I am a Data Engineer with over **6 years of experience** in designing, building, and optimizing **scalable data pipelines** for large-scale data processing. My expertise spans across **Hadoop, Spark, Kafka, Airflow, and Hive**, with a strong focus on **cloud-based ETL solutions** in **AWS, Azure, and GCP**. I specialize in **real-time streaming, data modeling, and performance optimization** to drive business intelligence and analytics.

ğŸ’¡ Passionate about **big data, cloud computing, and analytics**, transforming raw data into actionable insights.

---

## ğŸ”¹ Technical Skills
- **Programming:** Python, PySpark, Scala, SQL, Bash, Shell Scripting  
- **Big Data & Cloud:** Hadoop, Spark, Kafka, Airflow, AWS (S3, Redshift, Glue, Lambda), Azure (ADF, Synapse), GCP (BigQuery, Dataflow)  
- **Databases:** PostgreSQL, Oracle, DynamoDB, Cassandra, Snowflake, Redshift, MySQL  
- **ETL & Data Integration:** Apache NiFi, AWS Glue, Informatica, dbt  
- **CI/CD & DevOps:** Docker, Kubernetes, Terraform, Jenkins, Git, Airflow  
- **BI & Analytics:** Power BI, Tableau  
- **Streaming & Real-Time Processing:** Spark Streaming, Kafka, Kinesis  

---

## ğŸ’¼ Professional Experience

### **Data Engineer II | Medifast** *(May 2024 â€“ Present)*  
- Designed **real-time data ingestion** pipelines using **Spark Streaming** and **Kafka**, reducing data latency and enabling faster decision-making.
- Developed **ETL workflows** using **Airflow, dbt, and Snowflake**, ensuring seamless data transformation and high availability.
- Optimized **Spark jobs for distributed computing**, improving efficiency of large-scale data transformations.
- Implemented **data governance compliance** measures, ensuring data security and privacy across platforms.

### **Data Engineer II | Cencora** *(Jan 2023 â€“ May 2024)*  
- Built **automated data ingestion pipelines** using **Airflow** and **dbt**, improving data processing efficiency.
- Developed **custom reports** in Jupyter Notebooks, leveraging **Snowflake** for data analytics.
- Integrated **real-time data processing** with **Spark Streaming and Kafka**, enabling **quick anomaly detection**.
- Optimized **SQL query performance** for Snowflake and Redshift, cutting down operational costs by 20%.

### **Data Engineer I | Capgemini** *(Sep 2021 â€“ Dec 2022)*  
- Designed and implemented **RESTful APIs** using **MuleSoft** and **AWS API Gateway** for data integration.
- Implemented **CI/CD pipelines** using **GitHub Actions, Jenkins, and Terraform**, streamlining deployments.
- Built **self-healing data pipelines** with **auto-retries and fault tolerance** in Airflow.
- Optimized **BigQuery, Snowflake, and Redshift** workloads with clustering, partitioning, and indexing.

### **Data Engineer I | Macyâ€™s** *(Mar 2020 â€“ Aug 2021)*  
- Developed and maintained **Azure-based data pipelines** using **Azure Data Factory** and **Synapse Analytics**.
- Integrated **Adobe Analytics and GA4** for **customer insights and reporting**.
- Implemented **advanced SQL tuning** for **query performance optimization**.
- Automated **CI/CD workflows** using **GitHub Actions**, improving efficiency in data pipeline deployments.

### **Data Engineer I | Legato Health Technologies** *(Jan 2019 â€“ Feb 2020)*  
- Developed **scalable data solutions** using **AWS Redshift, Glue, and Lambda**.
- Automated **data validation processes**, improving compliance and reducing reporting errors.
- Collaborated with cross-functional teams to **enhance data accessibility and governance**.
- Designed **SQL-based transformations** to improve data consistency and integration across business applications.

---

## ğŸ“ Education
**Master of Science (M.S.) in Computer Science**  
ğŸ“ Kennesaw State University, Marietta, GA  

---

## ğŸ“« Connect with Me
ğŸ“§ Email: raghavenderthakur4@gmail.com  
[LinkedIn](#) | [GitHub](#) | [Portfolio](#) | [Medium](#)  

ğŸš€ Letâ€™s build something amazing together!

